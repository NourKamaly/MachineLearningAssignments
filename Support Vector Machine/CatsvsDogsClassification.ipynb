{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIsq8MT4YuTK",
    "outputId": "440847e9-673d-44e5-d3ee-ed9a2dc88580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "w84uIP1wZDPl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lzJebb_NqILl"
   },
   "outputs": [],
   "source": [
    "data_directory = \"/content/drive/MyDrive/Deep_learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dfc0MT-cZSfo"
   },
   "source": [
    "Here we are extracting the features from our pictures using HOG, by resizing our image to 128 x 64, having 9 orientations, 8 x 8 pixels per cells and 2 x 2 cells per block, we get 3780 feature in total (excluding the label), so a column for each feature is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QwEWAvFiekAU"
   },
   "outputs": [],
   "source": [
    "columns=[]\n",
    "for ctr in range(0,3780):\n",
    "    columns.append(str(ctr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w6UWCGa5ZhQr"
   },
   "outputs": [],
   "source": [
    "categories = [\"CatsTrain\",\"DogsTrain\",\"CatsTest\",\"DogsTest\"]\n",
    "\n",
    "def create_data(category):\n",
    "    path = os.path.join(data_directory,category)\n",
    "    df = pd.DataFrame (columns=columns)\n",
    "    for image in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path,image),cv2.IMREAD_GRAYSCALE)\n",
    "        resized_img = cv2.resize(img,(128,64))\n",
    "        fd,hog_img = hog(resized_img,orientations=9,pixels_per_cell=(8,8),cells_per_block=(2,2),visualize=True)\n",
    "        df.loc[len(df)] = fd.tolist()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vgLzjHsIgji3"
   },
   "outputs": [],
   "source": [
    "def merge_ready_randomize():\n",
    "    training_set = pd.DataFrame (columns=columns)\n",
    "    testing_set = pd.DataFrame (columns=columns)\n",
    "\n",
    "    training_set = pd.concat([catsTrain,dogsTrain],axis=0)\n",
    "    testing_set = pd.concat([catsTest,dogsTest],axis=0)\n",
    "\n",
    "    training_set['label'] = [1 if animal == 'cat' else 0 for animal in training_set['label']]\n",
    "    testing_set['label'] = [1 if animal == 'cat' else 0 for animal in testing_set['label']]\n",
    "\n",
    "    trainingSet = training_set.sample(frac=1,random_state = 26)\n",
    "    testing_set = testing_set.sample(frac=1,random_state = 26)\n",
    "  \n",
    "    return training_set,testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "J2phZY6nih2V"
   },
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    y_train = training_set['label']\n",
    "    x_train = training_set.drop(columns=['label'],axis=1)\n",
    "    y_test = testing_set['label']\n",
    "    x_test = testing_set.drop(columns=['label'],axis=1)\n",
    "    return x_train, x_test, y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Mt_yGS-QaeG4"
   },
   "outputs": [],
   "source": [
    "def trainSVMs(x_train,x_test,y_train,y_test):\n",
    "    for name, model in supportVectorMachines:\n",
    "        print(\"Training {modelName}\".format(modelName = name))\n",
    "        SVM = model.fit (x_train,y_train)\n",
    "        training_error = accuracy_score(SVM.predict(x_train),y_train)\n",
    "        testing_error = accuracy_score(SVM.predict(x_test),y_test)\n",
    "        print(\"Training error is {training_error}\".format(training_error=training_error))\n",
    "        print(\"Testing error is {testing_error}\".format(testing_error=testing_error))\n",
    "        print('-'*45)\n",
    "    print(\"Training an ensemble stacking classifier\")\n",
    "    classifier = StackingClassifier(estimators=supportVectorMachines,final_estimator=LogisticRegression(),cv=10).fit(x_train,y_train)\n",
    "    print(\"Training error is {training_error}\".format(training_error=training_error))\n",
    "    print(\"Testing error is {testing_error}\".format(testing_error=testing_error))\n",
    "    print('-'*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IkDgK7MwLIqm"
   },
   "outputs": [],
   "source": [
    "image_dataset =[]\n",
    "def create_image_dataset():\n",
    "    for category in categories:\n",
    "        path = os.path.join(data_directory,category)\n",
    "        class_index = categories.index(category)\n",
    "        if class_index== 0 or class_index==2:\n",
    "            class_index = 1\n",
    "        else :\n",
    "            class_index=0\n",
    "        for images in os.listdir(path):\n",
    "            try :\n",
    "                img_array= cv2.imread(os.path.join(path,images),cv2.IMREAD_GRAYSCALE)\n",
    "                resized_image = cv2.resize(img_array,(128,64))\n",
    "                image_dataset.append([resized_image,class_index])\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Hu7oDEbqnHVW"
   },
   "outputs": [],
   "source": [
    "def pvalue_feature_selection():\n",
    "    for column in training_set.columns:\n",
    "        if column != 'label':\n",
    "            corr,pvalue = stats.pearsonr(training_set[column],training_set['label'])\n",
    "            if pvalue >=0.05:\n",
    "                training_set.drop(columns=[column],axis = 1,inplace=True)\n",
    "                testing_set.drop(columns=[column],axis = 1,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iLM9veGQnQzf"
   },
   "outputs": [],
   "source": [
    "def select_k_best_feature_selection(x_train,y_train):\n",
    "    selector = SelectKBest(chi2)\n",
    "    selected_features = selector.fit_transform(x_train,y_train)\n",
    "    print(selected_features.shape)\n",
    "    filter = selector.get_support()\n",
    "    features = np.array(columns)\n",
    "    winning_features = features[filter]\n",
    "    print(\"Best 10 features are {features}\".format(features = winning_features))\n",
    "    for column in training_set:\n",
    "        if column != 'label' :\n",
    "            if column not in winning_features:\n",
    "                training_set.drop(columns=[column],axis=1,inplace=True)\n",
    "                testing_set.drop(columns=[column],axis=1,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WSzGf5pxh7D3"
   },
   "outputs": [],
   "source": [
    "catsTrain = create_data(categories[0])\n",
    "catsTrain['label'] = \"cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WrZJInQ7tX-7"
   },
   "outputs": [],
   "source": [
    "dogsTrain = create_data(categories[1])\n",
    "dogsTrain['label'] = \"dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zH1vxkuMOOx3"
   },
   "outputs": [],
   "source": [
    "catsTest = create_data(categories[2])\n",
    "catsTest['label'] = \"cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "buy40cPItbUG"
   },
   "outputs": [],
   "source": [
    "dogsTest = create_data(categories[3])\n",
    "dogsTest['label'] = \"dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10R3NzejXoHP",
    "outputId": "d4b961bb-e0c4-4e4f-c627-b05ca0f62a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape  (1000, 3781)\n",
      "Data shape  (1000, 3781)\n",
      "Data shape  (100, 3781)\n",
      "Data shape  (100, 3781)\n"
     ]
    }
   ],
   "source": [
    "for data in (catsTrain, dogsTrain,catsTest,dogsTest):\n",
    "    print(\"Data shape \" , data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNfoVtguZa25"
   },
   "source": [
    "Merging each dataframe into its training/testing set\n",
    "\n",
    "If the data is not randomized, the model will be biased to the first label that will exist in the first half of the dataset, then it will be biased to the second label that exist in the second half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iBkhV_CghW8l"
   },
   "outputs": [],
   "source": [
    "training_set, testing_set = merge_ready_randomize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqMmFlGDZxFR"
   },
   "source": [
    "# There are multiple ways to select features\n",
    "1. Pvalue\n",
    "2. SelectKBest\n",
    "\n",
    "# Why is feature selection necessary ?\n",
    " According to LaGrange interpolation techniques for finding a unique polynomial that \n",
    "passes through the observations, if the number of features (estimators/predictors) was \n",
    "more than the number of observations (data points), then the predictive line is not \n",
    "unique and the model is prone to overfitting, and this is the case here, 3780 features\n",
    "and 2000 observations, so some features had to be removed \n",
    "\n",
    "1. Pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5AoDHTWqoMiZ"
   },
   "outputs": [],
   "source": [
    "pvalue_feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LUghWqk6i8mS"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,y_test = split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DZO-_maMePsw"
   },
   "outputs": [],
   "source": [
    "supportVectorMachines = {(\"Polynomial Kernel SVM\",svm.SVC(kernel='poly')),\n",
    "                         (\"Linear Kernel SVM\",svm.SVC(kernel='linear')),\n",
    "                         (\"RBF Kernel SVM\",svm.SVC(kernel='rbf')),\n",
    "                         (\"Linear SVM\",svm.LinearSVC())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzXGXMpFdAIq",
    "outputId": "cd4722c5-e343-4582-b54c-e415eb5966c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Polynomial Kernel SVM\n",
      "Training error is 1.0\n",
      "Testing error is 0.735\n",
      "---------------------------------------------\n",
      "Training Linear Kernel SVM\n",
      "Training error is 0.9185\n",
      "Testing error is 0.73\n",
      "---------------------------------------------\n",
      "Training RBF Kernel SVM\n",
      "Training error is 0.9485\n",
      "Testing error is 0.725\n",
      "---------------------------------------------\n",
      "Training Linear SVM\n",
      "Training error is 0.976\n",
      "Testing error is 0.725\n",
      "---------------------------------------------\n",
      "Training an ensemble stacking classifier\n",
      "Training error is 0.976\n",
      "Testing error is 0.725\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainSVMs(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwKglP-2pd6m"
   },
   "source": [
    "2. SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "y8rX2w1XjYon"
   },
   "outputs": [],
   "source": [
    "training_set, testing_set = merge_ready_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZQGDG5lhlrep"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,y_test = split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vaGCVo4GoSuW",
    "outputId": "bdab56a5-9e37-47f8-cec1-4dd30dc17156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 10)\n",
      "Best 10 features are ['92' '587' '614' '879' '906' '987' '1014' '3473' '3491' '3626']\n"
     ]
    }
   ],
   "source": [
    "select_k_best_feature_selection(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmiJta9wltGb",
    "outputId": "95dff0b3-6a76-4f45-f8fd-eeff340c61bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Polynomial Kernel SVM\n",
      "Training error is 1.0\n",
      "Testing error is 0.705\n",
      "---------------------------------------------\n",
      "Training Linear Kernel SVM\n",
      "Training error is 0.997\n",
      "Testing error is 0.655\n",
      "---------------------------------------------\n",
      "Training RBF Kernel SVM\n",
      "Training error is 0.965\n",
      "Testing error is 0.745\n",
      "---------------------------------------------\n",
      "Training Linear SVM\n",
      "Training error is 1.0\n",
      "Testing error is 0.675\n",
      "---------------------------------------------\n",
      "Training an ensemble stacking classifier\n",
      "Training error is 1.0\n",
      "Testing error is 0.675\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainSVMs(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahL3pPrKs0Xr"
   },
   "source": [
    "Trying a CNN, but it is prone to overfitting due to the very small size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "F_dLd4PjMgJg"
   },
   "outputs": [],
   "source": [
    "create_image_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1w8vJ3ynL1cm"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "d_KxM6Q3MAsH"
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "for features, labels in image_dataset:\n",
    "    X.append(features)\n",
    "    Y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2G1aZhFLMBnA"
   },
   "outputs": [],
   "source": [
    "X= np.array(X).reshape(-1,128,64,1)\n",
    "Y = np.array(Y).reshape(2200,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NiO5ko-XM5Jd",
    "outputId": "19eea288-a030-449d-e57f-0146ded7ca20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 128, 64, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIokeKMhM7wZ",
    "outputId": "b9c7af48-4d33-4ab7-c8e1-4061891fb48f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "1rKX77m5MIKb"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(X,Y,test_size=0.1, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zq5Hz_PsSyXL"
   },
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "O9-_J4BnSyXL"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32,(3,3),activation = 'relu',input_shape=(128,64,1)),\n",
    "                                    tf.keras.layers.MaxPool2D(2,2),\n",
    "                                    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "                                  tf.keras.layers.Flatten(),\n",
    "                                  tf.keras.layers.Dense(64,activation='relu'),\n",
    "                                  tf.keras.layers.Dense(8,activation='relu'),\n",
    "                                   tf.keras.layers.Dense(1,activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Ra5cVrEySyXL"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01,momentum=0.8),loss = tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rv4vPe31SyXL",
    "outputId": "cd92d3ec-9f9b-41e8-a7ab-151ef7863454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "62/62 [==============================] - 19s 299ms/step - loss: 0.6951 - accuracy: 0.4854\n",
      "Epoch 2/30\n",
      "62/62 [==============================] - 18s 297ms/step - loss: 0.6934 - accuracy: 0.4859\n",
      "Epoch 3/30\n",
      "62/62 [==============================] - 18s 296ms/step - loss: 0.6924 - accuracy: 0.5293\n",
      "Epoch 4/30\n",
      "62/62 [==============================] - 20s 325ms/step - loss: 0.6917 - accuracy: 0.5359\n",
      "Epoch 5/30\n",
      "62/62 [==============================] - 18s 297ms/step - loss: 0.6899 - accuracy: 0.5540\n",
      "Epoch 6/30\n",
      "62/62 [==============================] - 19s 299ms/step - loss: 0.6894 - accuracy: 0.5485\n",
      "Epoch 7/30\n",
      "62/62 [==============================] - 19s 298ms/step - loss: 0.6866 - accuracy: 0.5657\n",
      "Epoch 8/30\n",
      "62/62 [==============================] - 19s 299ms/step - loss: 0.6819 - accuracy: 0.5788\n",
      "Epoch 9/30\n",
      "62/62 [==============================] - 19s 300ms/step - loss: 0.6782 - accuracy: 0.5798\n",
      "Epoch 10/30\n",
      "62/62 [==============================] - 19s 299ms/step - loss: 0.6712 - accuracy: 0.5949\n",
      "Epoch 11/30\n",
      "62/62 [==============================] - 18s 298ms/step - loss: 0.6767 - accuracy: 0.5753\n",
      "Epoch 12/30\n",
      "62/62 [==============================] - 18s 297ms/step - loss: 0.6703 - accuracy: 0.5793\n",
      "Epoch 13/30\n",
      "62/62 [==============================] - 19s 299ms/step - loss: 0.6629 - accuracy: 0.5960\n",
      "Epoch 14/30\n",
      "62/62 [==============================] - 20s 329ms/step - loss: 0.6615 - accuracy: 0.6066\n",
      "Epoch 15/30\n",
      "62/62 [==============================] - 18s 298ms/step - loss: 0.6468 - accuracy: 0.6207\n",
      "Epoch 16/30\n",
      "62/62 [==============================] - 19s 298ms/step - loss: 0.6480 - accuracy: 0.6157\n",
      "Epoch 17/30\n",
      "62/62 [==============================] - 18s 298ms/step - loss: 0.6357 - accuracy: 0.6505\n",
      "Epoch 18/30\n",
      "62/62 [==============================] - 18s 298ms/step - loss: 0.6247 - accuracy: 0.6475\n",
      "Epoch 19/30\n",
      "62/62 [==============================] - 18s 296ms/step - loss: 0.6293 - accuracy: 0.6535\n",
      "Epoch 20/30\n",
      "62/62 [==============================] - 18s 298ms/step - loss: 0.6097 - accuracy: 0.6808\n",
      "Epoch 21/30\n",
      "62/62 [==============================] - 18s 297ms/step - loss: 0.5871 - accuracy: 0.6879\n",
      "Epoch 22/30\n",
      "62/62 [==============================] - 18s 298ms/step - loss: 0.5392 - accuracy: 0.7374\n",
      "Epoch 23/30\n",
      "62/62 [==============================] - 18s 297ms/step - loss: 0.5121 - accuracy: 0.7586\n",
      "Epoch 24/30\n",
      "62/62 [==============================] - 20s 326ms/step - loss: 0.4608 - accuracy: 0.7909\n",
      "Epoch 25/30\n",
      "62/62 [==============================] - 18s 297ms/step - loss: 0.4216 - accuracy: 0.8040\n",
      "Epoch 26/30\n",
      "62/62 [==============================] - 18s 296ms/step - loss: 0.4154 - accuracy: 0.8131\n",
      "Epoch 27/30\n",
      "62/62 [==============================] - 18s 297ms/step - loss: 0.2732 - accuracy: 0.8934\n",
      "Epoch 28/30\n",
      "62/62 [==============================] - 18s 298ms/step - loss: 0.1958 - accuracy: 0.9338\n",
      "Epoch 29/30\n",
      "62/62 [==============================] - 18s 298ms/step - loss: 0.1241 - accuracy: 0.9601\n",
      "Epoch 30/30\n",
      "62/62 [==============================] - 19s 299ms/step - loss: 0.0727 - accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f508e27ca10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=30,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJCjFgwpSyXM",
    "outputId": "c962052c-faf3-4168-c02a-81f978d7d4a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 71ms/step - loss: 1.5957 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5957133769989014, 0.5]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CatsvsDogsClassification.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
